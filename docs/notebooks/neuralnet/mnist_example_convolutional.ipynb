{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Optimal adversaries for convolutional MNIST model\n",
    "\n",
    "This notebook gives an example where OMLT is used to find adversarial examples for a trained convolutional neural network. We follow the below steps:<br>\n",
    "1.) A convolutional neural network (CNN) with ReLU activation functions is trained to classify images from the MNIST dataset <br>\n",
    "2.) OMLT is used to generate a mixed-integer encoding of the trained CNN using the big-M formulation <br>\n",
    "3.) The model is optimized to find the maximum classification error (defined by an \"adversarial\" label) over a small input region <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Setup\n",
    "This notebook assumes you have a working PyTorch environment to train the neural network for classification. The neural network is then formulated in Pyomo using OMLT which therefore requires working Pyomo and OMLT installations.\n",
    "\n",
    "The required Python libraries used this notebook are as follows: <br>\n",
    "- `numpy`: used for manipulate input data <br>\n",
    "- `torch`: the machine learning language we use to train our neural network\n",
    "- `torchvision`: a package containing the MNIST dataset\n",
    "- `pyomo`: the algebraic modeling language for Python, it is used to define the optimization model passed to the solver\n",
    "- `omlt`: the package this notebook demonstates. OMLT can formulate machine learning models (such as neural networks) within Pyomo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import requisite packages\n",
    "#data manipulation\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "#pytorch for training neural network\n",
    "import torch, torch.onnx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "#pyomo for optimization\n",
    "import pyomo.environ as pyo\n",
    "\n",
    "#omlt for interfacing our neural network with pyomo\n",
    "from omlt import OmltBlock\n",
    "from omlt.neuralnet import FullSpaceNNFormulation\n",
    "from omlt.io.onnx import write_onnx_model_with_bounds, load_onnx_neural_network_with_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data and Train a Neural Network\n",
    "\n",
    "We begin by loading the MNIST dataset as `DataLoader` objects with pre-set training and testing batch sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set training and test batch sizes\n",
    "train_kwargs = {'batch_size': 64}\n",
    "test_kwargs = {'batch_size': 1000}\n",
    "\n",
    "#build DataLoaders for training and test sets\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "dataset2 = datasets.MNIST('../data', train=False, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the structure of the convolutional neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 10\n",
    "\n",
    "class Net(nn.Module):\n",
    "    #define layers of neural network\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1  = nn.Conv2d(1, 2, (4,4), (2,2), 0)\n",
    "        self.conv2  = nn.Conv2d(2, 2, (4,4), (2,2), 0)\n",
    "        self.hidden1 = nn.Linear(5*5*2, hidden_size)\n",
    "        self.output  = nn.Linear(hidden_size, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define forward pass of neural network\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.conv1(x)\n",
    "        self.x2 = self.relu(self.x1)\n",
    "        self.x3 = self.conv2(self.x2)\n",
    "        self.x4 = self.relu(self.x3)\n",
    "        self.x5 = self.hidden1(self.x4.view((-1,5*5*2)))\n",
    "        self.x6 = self.relu(self.x5)\n",
    "        self.x7 = self.output(self.x6)\n",
    "        x = self.softmax(self.x7)      \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next define simple functions for training and testing the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training function computes loss and its gradient on batch, and prints status after every 200 batches\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train(); criterion = nn.NLLLoss()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 200  == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "#testing function computes loss and prints overall model accuracy on test set\n",
    "def test(model, test_loader):\n",
    "    model.eval(); criterion = nn.NLLLoss(reduction='sum')\n",
    "    test_loss = 0; correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  \n",
    "            pred = output.argmax(dim=1, keepdim=True) \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the neural network on the dataset.\n",
    "Training here is performed using the `Adadelta` optimizer for five epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.301070\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.012006\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.381090\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.395724\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.263946\n",
      "\n",
      "Test set: Average loss: 0.3262, Accuracy: 9075/10000 (91%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.524031\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.282691\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.493126\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.268222\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.199386\n",
      "\n",
      "Test set: Average loss: 0.2783, Accuracy: 9183/10000 (92%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.396457\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.449215\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.221934\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.314683\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.140539\n",
      "\n",
      "Test set: Average loss: 0.2462, Accuracy: 9295/10000 (93%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.490455\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.305711\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.286548\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.306441\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.280397\n",
      "\n",
      "Test set: Average loss: 0.2280, Accuracy: 9360/10000 (94%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.212264\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.144381\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.381677\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.124658\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.205714\n",
      "\n",
      "Test set: Average loss: 0.2085, Accuracy: 9401/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define model and optimizer\n",
    "model = Net()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "#train CNN model for five epochs\n",
    "for epoch in range(5):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test(model, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a MIP Formulation for the Trained Convolutional Neural Network\n",
    "\n",
    "We are now ready to use OMLT to formulate the trained model within a Pyomo optimization model. The nonsmooth ReLU activation function requires using a full-space representation, which uses the `NeuralNetworkFormulation` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a neural network without the final `LogSoftmax` activation. Although this activation helps greatly in training the neural network model, it is not trivial to encode in the optimization model. The ranking of the output labels remains the same without the activation, so it can be omitted when finding optimal adversaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NoSoftmaxNet(nn.Module):\n",
    "    #define layers of neural network\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1  = nn.Conv2d(1, 2, (4,4), (2,2), 0)\n",
    "        self.conv2  = nn.Conv2d(2, 2, (4,4), (2,2), 0)\n",
    "        self.hidden1 = nn.Linear(5 * 5 * 2, hidden_size)\n",
    "        self.output  = nn.Linear(hidden_size, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    #define forward pass of neural network\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.conv1(x)\n",
    "        self.x2 = self.relu(self.x1)\n",
    "        self.x3 = self.conv2(self.x2)\n",
    "        self.x4 = self.relu(self.x3)\n",
    "        self.x5 = self.hidden1(self.x4.view((-1,5*5*2)))\n",
    "        self.x6 = self.relu(self.x5)\n",
    "        x = self.output(self.x6)    \n",
    "        return x\n",
    "\n",
    "#create neural network without LogSoftmax and load parameters from existing model\n",
    "model2 = NoSoftmaxNet()\n",
    "model2.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define an instance of the optimal adversary problem. We formulate the optimization problem as: <br>\n",
    "\n",
    "$\n",
    "\\begin{align*} \n",
    "& \\max_x \\ y_k - y_j \\\\\n",
    "& s.t. y_k = N_k(x) \\\\ \n",
    "&\\quad |x - \\bar{x}|_\\infty \\leq 0.05\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "where $\\bar{x}$ corresponds to an image in the test dataset with true label `j`, and $N_k(x)$ is the value of the CNN output corresponding to adversarial label `k` given input `x`. PyTorch needs to trace the model execution to export it to ONNX, so we also define a dummy input tensor `x_temp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load image and true label from test set with index 'problem_index'\n",
    "problem_index = 0\n",
    "image = dataset2[problem_index][0].detach().numpy()\n",
    "label = dataset2[problem_index][1]\n",
    "\n",
    "#define input region defined by infinity norm\n",
    "epsilon_infty = 1e-3\n",
    "lb = np.maximum(0, image - epsilon_infty)\n",
    "ub = np.minimum(1, image + epsilon_infty)\n",
    "\n",
    "#save input bounds as dictionary, note that the first index 0 corresponds to the single-channel input\n",
    "input_bounds = {}\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        input_bounds[(0,i,j)] = (float(lb[0][i,j]), float(ub[0][i,j])) \n",
    "    \n",
    "#define dummy input tensor    \n",
    "x = dataset2[problem_index][0].view(-1,1,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export the PyTorch model as an ONNX model and use `load_onnx_neural_network_with_bounds` to load it into OMLT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(suffix='.onnx', delete=False) as f:\n",
    "    #export neural network to ONNX\n",
    "    torch.onnx.export(\n",
    "        model2,\n",
    "        x,\n",
    "        f,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={\n",
    "            'input': {0: 'batch_size'},\n",
    "            'output': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    #write ONNX model and its bounds using OMLT\n",
    "    write_onnx_model_with_bounds(f.name, None, input_bounds)\n",
    "    #load the network definition from the ONNX model\n",
    "    network_definition = load_onnx_neural_network_with_bounds(f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check before creating the optimization model, we can print the properties of the neural network layers from `network_definition`. This allows us to check input/output sizes, as well as activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tInputLayer(input_size=[1, 28, 28], output_size=[1, 28, 28])\tlinear\n",
      "1\tConvLayer(input_size=[1, 28, 28], output_size=[2, 13, 13], strides=[2, 2], kernel_shape=(4, 4))\trelu\n",
      "2\tConvLayer(input_size=[2, 13, 13], output_size=[2, 5, 5], strides=[2, 2], kernel_shape=(4, 4))\trelu\n",
      "3\tDenseLayer(input_size=[1, 50], output_size=[1, 10])\trelu\n",
      "4\tDenseLayer(input_size=[1, 10], output_size=[1, 10])\tlinear\n"
     ]
    }
   ],
   "source": [
    "for layer_id, layer in enumerate(network_definition.layers):\n",
    "    print(f\"{layer_id}\\t{layer}\\t{layer.activation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can load `network_definition` as a full-space `FullSpaceNNFormulation` object.OMLT doesn't include a formulation for sigmoid, so define it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulation = FullSpaceNNFormulation(network_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve Optimal Adversary Problem in Pyomo\n",
    "\n",
    "We now encode the trained neural network in a Pyomo model from the `FullSpaceNNFormulation` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pyomo model\n",
    "m = pyo.ConcreteModel()\n",
    "\n",
    "#create an OMLT block for the neural network and build its formulation\n",
    "m.nn = OmltBlock()\n",
    "m.nn.build_formulation(formulation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define an adversarial label as the true label plus one (or zero if the true label is nine), as well as the objective function for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary = (label + 1) % 10\n",
    "m.obj = pyo.Objective(expr=(-(m.nn.outputs[0,adversary]-m.nn.outputs[0,label])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we solve the optimal adversary problem using a mixed-integer solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.5 \n",
      "Build Date: Oct 15 2020 \n",
      "\n",
      "command line - /home/jhjalvi/anaconda3/envs/tensorflow/bin/cbc -printingOptions all -import /tmp/tmptpf8ezli.pyomo.lp -stat=1 -solve -solu /tmp/tmptpf8ezli.pyomo.soln (default strategy 1)\n",
      "Option for printingOptions changed from normal to all\n",
      "Presolve 1243 (-2356) rows, 1675 (-1912) columns and 9017 (-5270) elements\n",
      "Statistics for presolved model\n",
      "Original problem has 398 integers (398 of which binary)\n",
      "Presolved problem has 171 integers (171 of which binary)\n",
      "==== 1665 zero objective 11 different\n",
      "1 variables have objective of -0.799653\n",
      "1 variables have objective of -0.692429\n",
      "1 variables have objective of -0.432872\n",
      "1 variables have objective of -0.381614\n",
      "1 variables have objective of -0.166969\n",
      "1 variables have objective of -0.0541137\n",
      "1665 variables have objective of 0\n",
      "1 variables have objective of 0.25157\n",
      "1 variables have objective of 0.258075\n",
      "1 variables have objective of 0.551109\n",
      "1 variables have objective of 0.969763\n",
      "==== absolute objective values 11 different\n",
      "1665 variables have objective of 0\n",
      "1 variables have objective of 0.0541137\n",
      "1 variables have objective of 0.166969\n",
      "1 variables have objective of 0.25157\n",
      "1 variables have objective of 0.258075\n",
      "1 variables have objective of 0.381614\n",
      "1 variables have objective of 0.432872\n",
      "1 variables have objective of 0.551109\n",
      "1 variables have objective of 0.692429\n",
      "1 variables have objective of 0.799653\n",
      "1 variables have objective of 0.969763\n",
      "==== for integers 171 zero objective 1 different\n",
      "171 variables have objective of 0\n",
      "==== for integers absolute objective values 1 different\n",
      "171 variables have objective of 0\n",
      "===== end objective counts\n",
      "\n",
      "\n",
      "Problem has 1243 rows, 1675 columns (10 with objective) and 9017 elements\n",
      "Column breakdown:\n",
      "0 of type 0.0->inf, 1142 of type 0.0->up, 0 of type lo->inf, \n",
      "362 of type lo->up, 0 of type free, 0 of type fixed, \n",
      "0 of type -inf->0.0, 0 of type -inf->up, 171 of type 0.0->1.0 \n",
      "Row breakdown:\n",
      "347 of type E 0.0, 0 of type E 1.0, 0 of type E -1.0, \n",
      "9 of type E other, 0 of type G 0.0, 0 of type G 1.0, \n",
      "0 of type G other, 716 of type L 0.0, 0 of type L 1.0, \n",
      "171 of type L other, 0 of type Range 0.0->1.0, 0 of type Range other, \n",
      "0 of type Free \n",
      "Continuous objective value is -2.12429 - 0.02 seconds\n",
      "Cgl0003I 3 fixed, 0 tightened bounds, 0 strengthened rows, 0 substitutions\n",
      "Cgl0004I processed model has 937 rows, 1367 columns (115 integer (115 of which binary)) and 11817 elements\n",
      "Cbc0038I Initial state - 72 integers unsatisfied sum - 20.8814\n",
      "Cbc0038I Pass   1: suminf.    0.00000 (0) obj. 11.809 iterations 335\n",
      "Cbc0038I Solution found of 11.809\n",
      "Cbc0038I Relaxing continuous gives 11.7955\n",
      "Cbc0038I Before mini branch and bound, 43 integers at bound fixed and 641 continuous\n",
      "Cbc0038I Full problem 937 rows 1367 columns, reduced to 619 rows 530 columns - 16 fixed gives 607, 518 - still too large\n",
      "Cbc0038I Full problem 937 rows 1367 columns, reduced to 554 rows 470 columns\n",
      "Cbc0038I Mini branch and bound improved solution from 11.7955 to 11.7944 (0.48 seconds)\n",
      "Cbc0038I Freeing continuous variables gives a solution of 11.7937\n",
      "Cbc0038I Round again with cutoff of 11.7921\n",
      "Cbc0038I Pass   2: suminf.    0.20702 (1) obj. 11.7921 iterations 174\n",
      "Cbc0038I Pass   3: suminf.    0.39088 (1) obj. 11.7921 iterations 64\n",
      "Cbc0038I Pass   4: suminf.    0.31986 (1) obj. 11.7921 iterations 254\n",
      "Cbc0038I Pass   5: suminf.    0.24400 (1) obj. 11.7921 iterations 35\n",
      "Cbc0038I Pass   6: suminf.    0.31986 (1) obj. 11.7921 iterations 49\n",
      "Cbc0038I Pass   7: suminf.    0.56513 (2) obj. 11.7921 iterations 321\n",
      "Cbc0038I Pass   8: suminf.    0.81697 (2) obj. 11.7921 iterations 63\n",
      "Cbc0038I Pass   9: suminf.    0.56513 (2) obj. 11.7921 iterations 66\n",
      "Cbc0038I Pass  10: suminf.    1.29356 (7) obj. 11.7921 iterations 295\n",
      "Cbc0038I Pass  11: suminf.    1.35733 (4) obj. 11.7921 iterations 165\n",
      "Cbc0038I Pass  12: suminf.    1.27012 (4) obj. 11.7921 iterations 13\n",
      "Cbc0038I Pass  13: suminf.    0.77889 (3) obj. 11.7921 iterations 57\n",
      "Cbc0038I Pass  14: suminf.    0.75944 (3) obj. 11.7921 iterations 7\n",
      "Cbc0038I Pass  15: suminf.    1.47773 (4) obj. 11.7921 iterations 33\n",
      "Cbc0038I Pass  16: suminf.    1.33195 (4) obj. 11.7921 iterations 20\n",
      "Cbc0038I Pass  17: suminf.    1.38082 (4) obj. 11.7921 iterations 56\n",
      "Cbc0038I Pass  18: suminf.    1.25857 (4) obj. 11.7921 iterations 18\n",
      "Cbc0038I Pass  19: suminf.    1.01070 (4) obj. 11.7921 iterations 326\n",
      "Cbc0038I Pass  20: suminf.    0.94775 (5) obj. 11.7921 iterations 16\n",
      "Cbc0038I Pass  21: suminf.    1.08402 (4) obj. 11.7921 iterations 63\n",
      "Cbc0038I Pass  22: suminf.    1.05834 (4) obj. 11.7921 iterations 6\n",
      "Cbc0038I Pass  23: suminf.    1.03028 (3) obj. 11.7921 iterations 72\n",
      "Cbc0038I Pass  24: suminf.    0.97431 (3) obj. 11.7921 iterations 10\n",
      "Cbc0038I Pass  25: suminf.    0.72150 (2) obj. 11.7921 iterations 87\n",
      "Cbc0038I Pass  26: suminf.    0.64025 (2) obj. 11.7921 iterations 33\n",
      "Cbc0038I Pass  27: suminf.    0.63795 (2) obj. 11.7921 iterations 65\n",
      "Cbc0038I Pass  28: suminf.    0.59735 (2) obj. 11.7921 iterations 12\n",
      "Cbc0038I Pass  29: suminf.    0.56341 (2) obj. 11.7921 iterations 324\n",
      "Cbc0038I Pass  30: suminf.    0.74595 (2) obj. 11.7921 iterations 42\n",
      "Cbc0038I Pass  31: suminf.    0.61016 (2) obj. 11.7921 iterations 40\n",
      "Cbc0038I No solution found this major pass\n",
      "Cbc0038I Before mini branch and bound, 14 integers at bound fixed and 517 continuous\n",
      "Cbc0038I Full problem 937 rows 1367 columns, reduced to 666 rows 669 columns - 46 fixed gives 617, 620 - still too large\n",
      "Cbc0038I Full problem 937 rows 1367 columns, reduced to 593 rows 599 columns - too large\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.70 seconds)\n",
      "Cbc0038I After 0.70 seconds - Feasibility pump exiting with objective of 11.7937 - took 0.55 seconds\n",
      "Cbc0012I Integer solution of 11.7937 found by feasibility pump after 0 iterations and 0 nodes (0.78 seconds)\n",
      "Cbc0038I Full problem 937 rows 1367 columns, reduced to 813 rows 1247 columns - 42 fixed gives 771, 1205 - still too large\n",
      "Cbc0012I Integer solution of 11.792721 found by DiveCoefficient after 944 iterations and 0 nodes (1.27 seconds)\n",
      "Cbc0031I 106 added rows had average density of 32.424528\n",
      "Cbc0013I At root node, 106 cuts changed objective from 11.777607 to 11.789992 in 10 passes\n",
      "Cbc0014I Cut generator 0 (Probing) - 1 row cuts average 16.0 elements, 0 column cuts (0 active)  in 0.013 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 1 (Gomory) - 381 row cuts average 82.5 elements, 0 column cuts (0 active)  in 0.022 seconds - new frequency is 1\n",
      "Cbc0014I Cut generator 2 (Knapsack) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.018 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 3 (Clique) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.000 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 4 (MixedIntegerRounding2) - 33 row cuts average 20.0 elements, 0 column cuts (0 active)  in 0.009 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 5 (FlowCover) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.019 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 6 (TwoMirCuts) - 295 row cuts average 54.4 elements, 0 column cuts (0 active)  in 0.025 seconds - new frequency is -100\n",
      "Cbc0010I After 0 nodes, 1 on tree, 11.792721 best solution, best possible 11.789992 (1.38 seconds)\n",
      "Cbc0012I Integer solution of 11.79261 found by DiveCoefficient after 1301 iterations and 4 nodes (2.22 seconds)\n",
      "Cbc0001I Search completed - best objective 11.79260967177679, took 1540 iterations and 7 nodes (2.45 seconds)\n",
      "Cbc0032I Strong branching done 172 times (2219 iterations), fathomed 1 nodes and fixed 13 variables\n",
      "Cbc0035I Maximum depth 3, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 11.7776 to 11.79\n",
      "Probing was tried 10 times and created 1 cuts of which 0 were active after adding rounds of cuts (0.013 seconds)\n",
      "Gomory was tried 22 times and created 447 cuts of which 0 were active after adding rounds of cuts (0.032 seconds)\n",
      "Knapsack was tried 10 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.018 seconds)\n",
      "Clique was tried 10 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 10 times and created 33 cuts of which 0 were active after adding rounds of cuts (0.009 seconds)\n",
      "FlowCover was tried 10 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.019 seconds)\n",
      "TwoMirCuts was tried 10 times and created 295 cuts of which 0 were active after adding rounds of cuts (0.025 seconds)\n",
      "ZeroHalf was tried 1 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                11.79260967\n",
      "Enumerated nodes:               7\n",
      "Total iterations:               1540\n",
      "Time (CPU seconds):             2.79\n",
      "Time (Wallclock seconds):       3.16\n",
      "\n",
      "Total time (CPU seconds):       2.82   (Wallclock seconds):       3.19\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Problem': [{'Name': 'unknown', 'Lower bound': 11.79260967, 'Upper bound': 11.79260967, 'Number of objectives': 1, 'Number of constraints': 1243, 'Number of variables': 1675, 'Number of binary variables': 398, 'Number of integer variables': 398, 'Number of nonzeros': 10, 'Sense': 'minimize'}], 'Solver': [{'Status': 'ok', 'User time': -1.0, 'System time': 2.82, 'Wallclock time': 3.19, 'Termination condition': 'optimal', 'Termination message': 'Model was solved to optimality (subject to tolerances), and an optimal solution is available.', 'Statistics': {'Branch and bound': {'Number of bounded subproblems': 7, 'Number of created subproblems': 7}, 'Black box': {'Number of iterations': 1540}}, 'Error rc': 0, 'Time': 3.2129950523376465}], 'Solution': [OrderedDict([('number of solutions', 0), ('number of solutions displayed', 0)])]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver = pyo.SolverFactory('cbc')\n",
    "solver.solve(m, tee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8f31a8284ce774e9ad8d309790c576c984c0620550967f9ef361ac8e66f487d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
