{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ML Surrogates for Chemical Processes with OMLT\n",
    "This notebook illustrates the use of TensorFlow Keras and OMLT to produce an ML surrogate based on data from a chemical process flowsheet.\n",
    "\n",
    "There are several reasons to build surrogate models for complex processes, even when higher fidelity models already exist (e.g., reduce model size, improve convergence reliability, replace models with externally compiled code and make them fully-equation oriented).\n",
    "\n",
    "In this example, we have an existing model for an auto-thermal reformer flowsheet that has been built using the IDAES-PSE package. IDAES-PSE is a Python package that is built on Pyomo and provides a framework for equation-oriented modeling and analysis of advanced energy systems. We use this package to generate data for our systems, and then we utilize this data in an optimization problem with OMLT. To learn more about IDAES, see the [IDAES-PSE Github Page](https://github.com/IDAES/IDAES-PSE) or [IDAES Read-the-docs](https://idaes-pse.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The Auto-thermal Reformer Process\n",
    "\n",
    "The figure below shows the reformer process as modeled in IDAES.\n",
    "\n",
    "![Reformer Flowsheet](../images/reformer.png)\n",
    "\n",
    "This model has 12 outputs of interest, the steam flowrate, the reformer duty, and the properties of the outlet stream, including temperature, pressure, and composition. We are interested modeling how these outputs change as a function of two operating (or input) variables: \n",
    "- the fraction of natural gas that bypasses the reformer\n",
    "- steam to natural gas flow ratio\n",
    "\n",
    "We have already used IDAES to generate a CSV file that contains the input and output data for 2800 data points for our system.\n",
    "\n",
    "In this example, we will train a ReLU model from our process data and then demonstrate that we can solve an optimization problem with that surrogate model. In realistic applications, this surrogate model would form part of a design or operations problem with a much larger flowsheet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Setup\n",
    "This notebook assumes you have a working Tensorflow environment in addition to necessary Python packages described here. We use Keras to train neural networks of interest for our example which requires the Python Tensorflow package. The neural networks are then formulated in Pyomo using OMLT which therefore requires working Pyomo and OMLT installations.\n",
    "\n",
    "The required Python libraries used this notebook are as follows: <br>\n",
    "- `pandas`: used for data import and management <br>\n",
    "- `tensorflow`: the machine learning language we use to train our neural network\n",
    "- `pyomo`: the algebraic modeling language for Python, it is used to define the optimization model passed to the solver\n",
    "- `onnx`: used to express trained neural network models\n",
    "- `omlt`: The package this notebook demonstates. OMLT can formulate machine learning models (such as neural networks) within Pyomo\n",
    "\n",
    "**NOTE:** This notebook also assumes you have a working MIP solver executable (e.g., CBC, Gurobi) to solve optimization problems in Pyomo. The open-source solver CBC is called by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: DEPRECATED: Declaring class 'OmltBlockData' derived from\n",
      "'_BlockData'. The class '_BlockData' has been renamed to 'BlockData'.\n",
      "(deprecated in 6.7.2) (called from\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/omlt/block.py:33)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # suppress CUDA warnings from tensorflow\n",
    "\n",
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "import pyomo.environ as pyo\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from omlt import OffsetScaling, OmltBlock\n",
    "from omlt.io.keras import load_keras_sequential\n",
    "from omlt.neuralnet import ReluBigMFormulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Bypass Fraction  NG Steam Ratio  Steam Flow  Reformer Duty        AR  \\\n",
      "0                 0.8        0.800000    0.193898    9806.732716  0.002662   \n",
      "1                 0.8        0.810526    0.196449    9846.047501  0.002660   \n",
      "2                 0.8        0.821053    0.199000    9885.419259  0.002657   \n",
      "3                 0.8        0.831579    0.201552    9924.849127  0.002654   \n",
      "4                 0.8        0.842105    0.204103    9964.338177  0.002651   \n",
      "...               ...             ...         ...            ...       ...   \n",
      "2795              0.1        1.157895    1.262887   39771.876388  0.004086   \n",
      "2796              0.1        1.168421    1.274368   39989.582852  0.004080   \n",
      "2797              0.1        1.178947    1.285849   40207.531167  0.004073   \n",
      "2798              0.1        1.189474    1.297330   40425.721366  0.004067   \n",
      "2799              0.1        1.200000    1.308811   40644.153425  0.004060   \n",
      "\n",
      "          C2H6      C3H8     C4H10       CH4        CO       CO2        H2  \\\n",
      "0     0.012120  0.002651  0.001515  0.369276  0.073971  0.032251  0.208494   \n",
      "1     0.012107  0.002648  0.001513  0.368883  0.073684  0.032432  0.208507   \n",
      "2     0.012094  0.002646  0.001512  0.368491  0.073398  0.032612  0.208519   \n",
      "3     0.012082  0.002643  0.001510  0.368100  0.073114  0.032791  0.208529   \n",
      "4     0.012069  0.002640  0.001509  0.367710  0.072832  0.032968  0.208537   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2795  0.000517  0.000113  0.000065  0.016104  0.103440  0.054146  0.330923   \n",
      "2796  0.000516  0.000113  0.000064  0.016073  0.103003  0.054335  0.330682   \n",
      "2797  0.000515  0.000113  0.000064  0.016043  0.102569  0.054521  0.330439   \n",
      "2798  0.000514  0.000112  0.000064  0.016013  0.102138  0.054706  0.330196   \n",
      "2799  0.000513  0.000112  0.000064  0.015984  0.101710  0.054889  0.329953   \n",
      "\n",
      "           H2O        N2  \n",
      "0     0.070771  0.226288  \n",
      "1     0.071514  0.226050  \n",
      "2     0.072258  0.225813  \n",
      "3     0.073000  0.225577  \n",
      "4     0.073743  0.225341  \n",
      "...        ...       ...  \n",
      "2795  0.152351  0.338256  \n",
      "2796  0.153420  0.337714  \n",
      "2797  0.154487  0.337174  \n",
      "2798  0.155552  0.336636  \n",
      "2799  0.156616  0.336099  \n",
      "\n",
      "[2800 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# read in our csv data\n",
    "columns = [\n",
    "    \"Bypass Fraction\",\n",
    "    \"NG Steam Ratio\",\n",
    "    \"Steam Flow\",\n",
    "    \"Reformer Duty\",\n",
    "    \"AR\",\n",
    "    \"C2H6\",\n",
    "    \"C3H8\",\n",
    "    \"C4H10\",\n",
    "    \"CH4\",\n",
    "    \"CO\",\n",
    "    \"CO2\",\n",
    "    \"H2\",\n",
    "    \"H2O\",\n",
    "    \"N2\",\n",
    "]\n",
    "df = pd.read_csv(\"../data/reformer.csv\", usecols=columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# separate the data into inputs and outputs\n",
    "inputs = [\"Bypass Fraction\", \"NG Steam Ratio\"]\n",
    "outputs = [\n",
    "    \"Steam Flow\",\n",
    "    \"Reformer Duty\",\n",
    "    \"AR\",\n",
    "    \"C2H6\",\n",
    "    \"C3H8\",\n",
    "    \"C4H10\",\n",
    "    \"CH4\",\n",
    "    \"CO\",\n",
    "    \"CO2\",\n",
    "    \"H2\",\n",
    "    \"H2O\",\n",
    "    \"N2\",\n",
    "]\n",
    "dfin = df[inputs]\n",
    "dfout = df[outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We scale the data for improved training, however, we want to formulate\n",
    "# our optimizaton problem on the original variables. Therefore, we keep\n",
    "# the scaling parameters to use later in our optimization formulation\n",
    "\n",
    "x_offset, x_factor = dfin.mean().to_dict(), dfin.std().to_dict()\n",
    "y_offset, y_factor = dfout.mean().to_dict(), dfout.std().to_dict()\n",
    "\n",
    "dfin = (dfin - dfin.mean()).divide(dfin.std())\n",
    "dfout = (dfout - dfout.mean()).divide(dfout.std())\n",
    "\n",
    "# capture the minimum and maximum values of the scaled inputs\n",
    "# so we don't use the model outside the valid range\n",
    "scaled_lb = dfin.min()[inputs].to_numpy()\n",
    "scaled_ub = dfin.max()[inputs].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# create our Keras Sequential model\n",
    "nn = Sequential(name=\"reformer_relu_4_20\")\n",
    "nn.add(Dense(units=10, input_dim=len(inputs), activation=\"relu\"))\n",
    "nn.add(Dense(units=10, activation=\"relu\"))\n",
    "nn.add(Dense(units=10, activation=\"relu\"))\n",
    "nn.add(Dense(units=10, activation=\"relu\"))\n",
    "nn.add(Dense(units=len(outputs)))\n",
    "nn.compile(optimizer=Adam(), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.9315\n",
      "Epoch 2/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6021  \n",
      "Epoch 3/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.2147\n",
      "Epoch 4/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.0938\n",
      "Epoch 5/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0583\n",
      "Epoch 6/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0440\n",
      "Epoch 7/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.0354\n",
      "Epoch 8/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0265  \n",
      "Epoch 9/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.0208\n",
      "Epoch 10/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0171\n",
      "Epoch 11/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.0149\n",
      "Epoch 12/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.0121\n",
      "Epoch 13/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102\n",
      "Epoch 14/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.0084\n",
      "Epoch 15/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.0074\n",
      "Epoch 16/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.0061\n",
      "Epoch 17/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.0055\n",
      "Epoch 18/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0050\n",
      "Epoch 19/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.0046\n",
      "Epoch 20/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.0044\n",
      "Epoch 21/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.0038\n",
      "Epoch 22/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0037\n",
      "Epoch 23/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.0033\n",
      "Epoch 24/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.0030\n",
      "Epoch 25/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0028\n",
      "Epoch 26/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.0027\n",
      "Epoch 27/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026\n",
      "Epoch 28/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 0.0026\n",
      "Epoch 29/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.0024\n",
      "Epoch 30/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022\n",
      "Epoch 31/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.0022\n",
      "Epoch 32/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0021\n",
      "Epoch 33/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.0019\n",
      "Epoch 34/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.0018\n",
      "Epoch 35/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 36/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.0017\n",
      "Epoch 37/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.0016\n",
      "Epoch 38/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0015\n",
      "Epoch 39/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0014\n",
      "Epoch 40/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 \n",
      "Epoch 41/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014\n",
      "Epoch 42/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.0014\n",
      "Epoch 43/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013  \n",
      "Epoch 44/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.0013\n",
      "Epoch 45/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.0013\n",
      "Epoch 46/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.0012\n",
      "Epoch 47/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0012\n",
      "Epoch 48/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.0011  \n",
      "Epoch 49/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011  \n",
      "Epoch 50/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.0011\n",
      "Epoch 51/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011    \n",
      "Epoch 52/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.0010  \n",
      "Epoch 53/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0010  \n",
      "Epoch 55/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 9.7793e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5539e-04  \n",
      "Epoch 58/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 9.8643e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 9.5467e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5569e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 8.9545e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 8.9153e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 8.8198e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 8.7606e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 8.2828e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4195e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 8.8572e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8402e-04  \n",
      "Epoch 69/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 7.8691e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 8.2283e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 7.8774e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 7.3661e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 7.9336e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 7.3721e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 7.4315e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2666e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 7.2654e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9702e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.8081e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.0167e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 7.1075e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 6.6085e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 6.5808e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 6.1667e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 6.0925e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 6.3800e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.2445e-04  \n",
      "Epoch 88/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 6.2050e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.9191e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 6.0064e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 5.6989e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 6.0071e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 5.7475e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 5.8762e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.9248e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 5.6154e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5977e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5252e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 5.4744e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 5.6862e-04\n"
     ]
    }
   ],
   "source": [
    "# train our model\n",
    "x = dfin.to_numpy()\n",
    "y = dfout.to_numpy()\n",
    "\n",
    "history = nn.fit(x, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "# While not technically necessary, this shows how we can load a previously saved model into\n",
    "# our optimization formulation)\n",
    "nn.save(\"reformer_nn_relu.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optimization Problem\n",
    "In this small example, we will formulate a simple optimization problem that seeks to maximize the concentration of Hydrogen in the outlet while placing an upper bound on the Nitrogen concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# first, create the Pyomo model\n",
    "m = pyo.ConcreteModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create the OmltBlock to hold the neural network model\n",
    "m.reformer = OmltBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the Keras model\n",
    "nn_reformer = keras.models.load_model(\"reformer_nn_relu.keras\", compile=False)\n",
    "\n",
    "# Note: The neural network is in the scaled space. We want access to the\n",
    "# variables in the unscaled space. Therefore, we need to tell OMLT about the\n",
    "# scaling factors\n",
    "scaler = OffsetScaling(\n",
    "    offset_inputs={i: x_offset[inputs[i]] for i in range(len(inputs))},\n",
    "    factor_inputs={i: x_factor[inputs[i]] for i in range(len(inputs))},\n",
    "    offset_outputs={i: y_offset[outputs[i]] for i in range(len(outputs))},\n",
    "    factor_outputs={i: y_factor[outputs[i]] for i in range(len(outputs))},\n",
    ")\n",
    "\n",
    "scaled_input_bounds = {i: (scaled_lb[i], scaled_ub[i]) for i in range(len(inputs))}\n",
    "\n",
    "# create a network definition from the Keras model\n",
    "net = load_keras_sequential(\n",
    "    nn_reformer, scaling_object=scaler, scaled_input_bounds=scaled_input_bounds\n",
    ")\n",
    "\n",
    "# create the variables and constraints for the neural network in Pyomo\n",
    "m.reformer.build_formulation(ReluBigMFormulation(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# now add the objective and the constraints\n",
    "h2_idx = outputs.index(\"H2\")\n",
    "n2_idx = outputs.index(\"N2\")\n",
    "m.obj = pyo.Objective(expr=m.reformer.outputs[h2_idx], sense=pyo.maximize)\n",
    "m.con = pyo.Constraint(expr=m.reformer.outputs[n2_idx] <= 0.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# now solve the optimization problem (this may take some time)\n",
    "solver = pyo.SolverFactory(\"cbc\")\n",
    "status = solver.solve(m, tee=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bypass Fraction: 0.1\n",
      "NG Steam Ratio: 1.1404918\n",
      "H2 Concentration: 0.33255362\n",
      "N2 Concentration: 0.34\n"
     ]
    }
   ],
   "source": [
    "print(\"Bypass Fraction:\", pyo.value(m.reformer.inputs[0]))\n",
    "print(\"NG Steam Ratio:\", pyo.value(m.reformer.inputs[1]))\n",
    "print(\"H2 Concentration:\", pyo.value(m.reformer.outputs[h2_idx]))\n",
    "print(\"N2 Concentration:\", pyo.value(m.reformer.outputs[n2_idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
